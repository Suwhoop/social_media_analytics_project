---
title: "Social Media Analytics Notebook Matt"
output: html_notebook
---

#### Add any Libs needed here

```{r}
library(dplyr)
library(tidyverse)
library(caTools)
library(caret)
library(ROCR)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(caret)
library(rpart)
library(ggcorrplot)


```

#### Bringing in the data, file is stored in github so no need to download 

```{r}
urlfile<-'https://raw.githubusercontent.com/Suwhoop/social_media_analytics_project/master/High_Note_data.csv'
data_raw<-read.csv(url(urlfile))
data_raw  <- data_raw[complete.cases(data_raw[,0:23]),] ### Removing rows where adopter is NA
```

#### Inital data exploration 
```{r}
head(data_raw) #### we will need to keep NAs in mind (potential omit in some models)
```

```{r}
summary(data_raw) #### Looks like there are some significantly negative deltas related to finds 
```

```{r}
data_adopters <- data_raw[data_raw$adopter %in% 1,]
summary(data_adopters) #### looks like adopters are older, have more friends, and more international friends 
head(data_adopters)
```

#### Correlation Analysis

```{r}
corCancer <- cor(data_raw[2:13])
ggcorrplot(corCancer)
cortable <- corCancer
cortable
```

#### Split Data into Training and Testing
```{r}
sample_size = floor(0.7*nrow(data_raw))
set.seed(777)

# randomly split data with NAs
picked = sample(seq_len(nrow(data_raw)),size = sample_size)
train_hn =data_raw[picked,]
test_hn =data_raw[-picked,]

train_hn_final = train_hn[2:12]
train_hn_final$adopter <- train_hn$adopter 
test_hn_final = test_hn[2:12]
test_hn_final$adopter = test_hn$adopter


# randomly split data without NAs
data_no_na  <- data_raw[complete.cases(data_raw[,2:12]),]
sample_size_no_na = floor(0.7*nrow(data_no_na))
picked_no_na = sample(seq_len(nrow(data_no_na)),size = sample_size_no_na)
train_hn_no_na =data_no_na[picked,]
test_hn_no_na =data_no_na[-picked,]
```

```{r}
train_hn_rf <- train_hn_no_na[0:12]
test_hn_rf <- test_hn_no_na[0:12]
train_hn_rf$adopter <- train_hn_no_na$adopter
test_hn_rf$adopter <- test_hn_no_na$adopter
train_hn_rf
```

```{r}
head(train_hn_final)
```

#### Logistic Regression

```{r}

#### Removed posts from logi model after inital run, not significant 
#### After removing NA adopter rows, avg male friend and shouts were not significant so I removed them

logi_model = glm(adopter ~ age + male + friend_cnt + avg_friend_age + friend_country_cnt + songsListened + lovedTracks + playlists, family = binomial, data = train_hn_final)
summary(logi_model)

#### Removed posts and avg friend male from logi model no na after inital run, not significant 
#### After removing NA adopter rows, shouts were not significant so I removed them
#### Depricated after seeing NAs had no impact once NA adopter rows were excluded 

####### logi_model_no_na = glm(adopter ~ age + male + friend_cnt + avg_friend_age + friend_country_cnt + subscriber_friend_cnt + songsListened + lovedTracks + playlists, family = binomial, data = train_hn_no_na)

#### Added second logi model to compare subscriber_friend_cnt
logi_model_sfc = glm(adopter ~ age + male + avg_friend_age + friend_country_cnt + subscriber_friend_cnt + songsListened + lovedTracks + playlists, family = binomial, data = train_hn_final)
summary(logi_model_sfc)

```

```{r}

#### Once I removed the adopter NAs the other NAs had not impact on the logistic regression models, however the models are extremely poor at making a true positive prodiction (~44% accurate)

#### Data w/ NAs
pred.full = predict(logi_model, newdata=test_hn_final, type="response")
classify.full = (pred.full > 0.1)

class_prediction = factor(pred.full > 0.1, levels = c(F, T), 
                             labels = c("Freemium", "Subscriber"))

actual = factor(test_hn$adopter, levels = c(0, 1), 
                      labels = c("Freemium", "Subscriber"))

cm = table(actual, class_prediction)
cm

#### Data w/o NAs
#### Depricated 
#### pred.full.no.na = predict(logi_model_no_na, newdata=test_hn_no_na, type="response")
#### classify.full.no.na = (pred.full > 0.1)

#### class_prediction_no_na = factor(pred.full.no.na > 0.1, levels = c(F, T), 
                      ####       labels = c("Freemium", "Subscriber"))

#### actual_no_na = factor(test_hn_no_na$adopter, levels = c(0, 1), 
                      #### labels = c("Freemium", "Subscriber"))

#### cm_no_na = table(actual_no_na, class_prediction_no_na)
#### cm_no_na

pred.full.sfc = predict(logi_model_sfc, newdata=test_hn_final, type="response")
classify.full.sfc = (pred.full.sfc > 0.1)

class_prediction_sfc = factor(pred.full.sfc > 0.1, levels = c(F, T), 
                             labels = c("Freemium", "Subscriber"))

actual_sfc = factor(test_hn$adopter, levels = c(0, 1), 
                      labels = c("Freemium", "Subscriber"))

cm_sfc = table(actual_sfc, class_prediction_sfc)
cm_sfc

```

```{r}
ACC = sum(diag(cm)) / sum(cm) 
ACC

TPR = cm[2,2] / sum(cm[2,])  
TPR

FPR = cm[1,2] / sum(cm[1,])
FPR

TNR = cm[1,1] / sum(cm[1,]) 
TNR

FNR = cm[2,1] / sum(cm[2,])
FNR
```

```{r}
ACC_sfc = sum(diag(cm_sfc)) / sum(cm_sfc) 
ACC_sfc

TPR_sfc = cm_sfc[2,2] / sum(cm_sfc[2,])  
TPR_sfc

FPR_sfc = cm_sfc[1,2] / sum(cm_sfc[1,])
FPR_sfc

TNR_sfc = cm_sfc[1,1] / sum(cm_sfc[1,]) 
TNR_sfc

FNR_sfc = cm_sfc[2,1] / sum(cm_sfc[2,])
FNR_sfc
```


#### CART

```{r}
#### Model Training 
set.seed(123)
cart_tree_1 = rpart(adopter ~.,data = train_hn_final, method = "class", cp = 0.0008)
prp(cart_tree_1)
```

```{r}
CART_importance_scores = cart_tree_1$variable.importance
n_variables = 12 # how many variables to display
barplot( tail( sort(CART_importance_scores), n_variables ),
         beside = TRUE,
         horiz = TRUE,
         las=1,
         main = paste("CART - top", n_variables, "importance scores"),
         cex.names =.7)
```


#### Random Forest

```{r}
#### This can take a minute or two
train_hn_final$adopter <- factor(train_hn_final$adopter)
set.seed(51)
rf_model <- train(adopter ~ ., data = train_hn_final, method = 'rf', trControl = trainControl(method = 'cv', number = 5))
```

```{r}
prp(rf_model)
```

